from app.services.vector_store import VectorStore
from app.models import DocumentChunk
from app import db
from app.services.ai_service import AIService
import logging

def rebuild_index_from_db():
    """Rebuild the vector index from database documents on app startup"""
    print("üîÑ Rebuilding vector index from database...")
    logging.info("Starting vector index rebuild from database")

    try:
        # Query all document chunks from the database
        chunks = DocumentChunk.query.all()

        if not chunks:
            print("‚ö†Ô∏è No chunks found in DB")
            logging.info("No document chunks found in database")
            return

        print(f"Found {len(chunks)} chunks in database")
        logging.info(f"Found {len(chunks)} document chunks to index")

        # Extract text content and metadata from chunks
        texts = [c.chunk_text for c in chunks]
        metadatas = [
            {
                'text': c.chunk_text,
                'doc_id': c.document_id,
                'chunk_id': c.id,
                'page_num': getattr(c, 'page_num', None)  # if page info exists
            } 
            for c in chunks
        ]

        # Get the singleton vector store instance
        vector_store = VectorStore.get_instance()
        
        # Clear existing index and rebuild from database content
        vector_store.clear()
        
        if texts:
            total_chunks = len(texts)
            print(f"Adding {total_chunks} texts to vector store in batches...")
            logging.info(f"Adding {total_chunks} texts to vector store in batches...")
            
            # Prepare metadata
            metadatas = [
                {
                    'text': c.chunk_text,
                    'doc_id': c.document_id,
                    'chunk_id': c.id,
                    'page_num': getattr(c, 'page_num', None)  # if page info exists
                } 
                for c in chunks
            ]
            
            # Optimized batch processing with larger batches and progress tracking
            BATCH_SIZE = 64  # Increased from 32 for better throughput
            successful_batches = 0
            failed_batches = 0
            
            # Process in larger batches for better performance
            for i in range(0, total_chunks, BATCH_SIZE):
                batch_texts = texts[i:i + BATCH_SIZE]
                batch_metas = metadatas[i:i + BATCH_SIZE]
                
                try:
                    # Use the new add_texts method which handles embedding internally
                    vector_store.add_texts(batch_texts, batch_metas)
                    successful_batches += 1
                    
                    # Progress reporting every 5 batches instead of every batch
                    if (i // BATCH_SIZE) % 5 == 0 or i + BATCH_SIZE >= total_chunks:
                        progress = min(i + BATCH_SIZE, total_chunks)
                        print(f"Progress: {progress}/{total_chunks} chunks processed ({successful_batches} batches successful)")
                        logging.info(f"Progress: {progress}/{total_chunks} chunks processed")
                        
                except Exception as e:
                    failed_batches += 1
                    logging.error(f"Failed to process batch ending at index {i + BATCH_SIZE}: {e}")
                    # Continue with remaining batches instead of stopping
                    continue
            
            print(f"‚úÖ Rebuilt index. Processed {successful_batches} batches successfully, {failed_batches} failed.")
            logging.info(f"Successfully rebuilt vector index. {successful_batches} batches successful, {failed_batches} failed.")
            
            # Log final stats - THIS IS CRITICAL FOR DEBUGGING
            stats = vector_store.get_stats()
            print(f"üìä Final vector store stats: {stats}")
            logging.info(f"Final vector store stats: {stats}")
            
            # Double-check that the index is actually populated
            if stats['total_vectors'] > 0:
                print(f"‚úÖ Vector store is ready with {stats['total_vectors']} vectors")
                logging.info(f"‚úÖ Vector store is ready with {stats['total_vectors']} vectors")
            else:
                print("‚ùå WARNING: Vector store has 0 vectors after rebuild!")
                logging.warning("‚ùå WARNING: Vector store has 0 vectors after rebuild!")
        else:
            print("‚ö†Ô∏è No text content to index")
            logging.info("No text content found to index")

    except Exception as e:
        print(f"‚ùå Error rebuilding index from DB: {e}")
        logging.error(f"Error rebuilding vector index from database: {e}", exc_info=True)
        raise